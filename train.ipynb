{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hello, user! This notebook will walk you through the training process of an object detection model using transfer learning from Tensorflow Object Detection API. Please run all the relevant cells in order. Text paragraphs like these will not fully substitute conventional Python comments but will serve as additonal commentary on the process. <br>\n",
    "Ensure that the kernel is Python version 3.9.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import relevant libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not much to be said here, just importing libraries. Justification for libraries used are found in the comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os # To run terminal commands\n",
    "import tensorflow as tf # Google's Machine Learning frameowrk. using for Transfer training.\n",
    "from object_detection.utils import config_util # Add-on for Tensorflow\n",
    "from object_detection.protos import pipeline_pb2 # Add-on for Tensorflow\n",
    "from google.protobuf import text_format # Add-on for Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Generate TF records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF record files hold the necessary data for training a model. <br>\n",
    "Ensure that your images and labels for each individual image are in the following folders before proceeding with this step. <br>\n",
    "Training images: `./Tensorflow/workspace/images/train`<br>\n",
    "Test images: `./Tensorflow/workspace/images/test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating train.record\")\n",
    "os.system(\"python Tensorflow/scripts/generate_tfrecord.py -x Tensorflow/workspace/images/train -l Tensorflow/Workspace/annotations/label_map.pbtxt -o Tensorflow/workspace/annotations/train.record\")\n",
    "print(\"Generating test.record\")\n",
    "os.system(\"python Tensorflow/scripts/generate_tfrecord.py -x Tensorflow/workspace/images/test -l Tensorflow/Workspace/annotations/label_map.pbtxt -o Tensorflow/workspace/annotations/test.record\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create the label map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The label map is the file that contains the labels for the different category of items. The file needs to be generated according to the labels to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <------------------------------------Generate label map------------------------------------>\n",
    "while True: # running input validation for an integer\n",
    "  num = (\"Enter the number of types of items/objects (between 0 to 100) to be detected: \") # Get user input on the number of labels\n",
    "  try:\n",
    "    num = int(num)\n",
    "    if num > 0 and num < 100:\n",
    "      break\n",
    "    else:\n",
    "      print(\"Error: input format is invalid. Please try again.\")\n",
    "  except:\n",
    "    print(\"Error: input format is invalid. Please try again.\")\n",
    "label_map = []\n",
    "for x in num:\n",
    "  label = input(\"Enter label name for item \" + str(x) + \": \") # Get user input on label names\n",
    "  label_map.append({\"name\": label, \"num\": x})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Tensorflow/workspace/annotations\" + '/label_map.pbtxt', 'w') as f: # Write label map file\n",
    "    for x in label_map:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(x['name']))\n",
    "        f.write('\\tid:{}\\n'.format(x['id']))\n",
    "        f.write('}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Create and set-up relevant paths for model directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input the name for the model and the code will create the model directpry, as well as import the template model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <------------------------------------Create model directory------------------------------------>\n",
    "model_name = input(\"Enter name for the model\") # Get use input for custom model name\n",
    "os.system(\"mkdir Tensorflow/workspace/models/\" + model_name) # Creates directory to store all model-related files\n",
    "os.system(\"cp Tensorflow/workspace/pre-trained-models/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config Tensorflow/workspace/models/\" + model_name) # Copy template model config file into custom model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Set up and configure config file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all has been done successfully, just run the following block of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <------------------------------------Configure config file------------------------------------>\n",
    "config_file_path = \"Tensorflow/workspace/models/\" + model_name + \"/pipeline.config\"\n",
    "config = config_util.get_configs_from_pipeline_file(config_file_path)\n",
    "\n",
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(config_file_path, \"r\") as f:                                                      \n",
    "    proto_str = f.read()                                                                                                  \n",
    "    text_format.Merge(proto_str, pipeline_config)\n",
    "\n",
    "# <------------------------------------Settings for config file------------------------------------>\n",
    "while True:\n",
    "    batch_size = input(\"Default batch size is 4. Max batch size is 10. Enter custom batch size: \") # User input for batch size for training\n",
    "    if str(batch_size) == \"\":\n",
    "        batch_size = 4\n",
    "        break\n",
    "    try:\n",
    "        batch_size = int(batch_size)\n",
    "        if batch_size > 0 and batch_size < 11:\n",
    "            break\n",
    "        else:\n",
    "            print(\"Error: Input format is invalid. Please try again.\")\n",
    "    except:\n",
    "        print(\"Error: Input format is invalid. Please try again.\")\n",
    "\n",
    "\n",
    "pipeline_config.model.ssd.num_classes = num\n",
    "pipeline_config.train_config.batch_size = batch_size\n",
    "pipeline_config.train_config.fine_tune_checkpoint = \"Tensorflow/workspace/pre-trained-models/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0\"\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.label_map_path= \"Tensorflow/Workspace/annotations/label_map.pbtxt\"\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [\"Tensorflow/Workspace/annotations/train.record\"]\n",
    "pipeline_config.eval_input_reader[0].label_map_path = \"Tensorflow/Workspace/annotations/label_map.pbtxt\"\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [\"Tensorflow/Workspace/annotations/test.record\"]\n",
    "\n",
    "# Write to the config file\n",
    "config_text = text_format.MessageToString(pipeline_config)                                                                       \n",
    "with tf.io.gfile.GFile(config_file_path, \"wb\") as f:\n",
    "    f.write(config_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Generating Terminal command for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're done! Run the following block of code to generate the Terminal command. Paste the following command into the Terminal from this directory and training will commence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Preparation for training complete. Training shall now commence\")\n",
    "print(\"Please copy and paste the following program into your Terminal within this directory.\")\n",
    "print(\"\"\"python Tensorflow/workspace/model_main_tf2.py --model_dir=Tensorflow/workspace/models/{} --pipeline_config_path=Tensorflow/workspace/models/{}/pipeline.config --num_train_steps=10000\"\"\".format(model_name,model_name)) # Generate Terminal command for user to run\n",
    "print(\"This program will now terminate. All the best with the training!\")\n",
    "exit()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
